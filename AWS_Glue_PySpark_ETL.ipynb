{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "# Glue Studio Notebook\n",
    "You are now running a **Glue Studio** notebook; before you can start using your notebook you *must* start an interactive session.\n",
    "\n",
    "## Available Magics\n",
    "|          Magic              |   Type       |                                                                        Description                                                                        |\n",
    "|-----------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| %%configure                 |  Dictionary  |  A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics. |\n",
    "| %profile                    |  String      |  Specify a profile in your aws configuration to use as the credentials provider.                                                                          |\n",
    "| %iam_role                   |  String      |  Specify an IAM role to execute your session with.                                                                                                        |\n",
    "| %region                     |  String      |  Specify the AWS region in which to initialize a session.                                                                                                 |\n",
    "| %session_id                 |  String      |  Returns the session ID for the running session.                                                                                                          |\n",
    "| %connections                |  List        |  Specify a comma separated list of connections to use in the session.                                                                                     |\n",
    "| %additional_python_modules  |  List        |  Comma separated list of pip packages, s3 paths or private pip arguments.                                                                                 |\n",
    "| %extra_py_files             |  List        |  Comma separated list of additional Python files from S3.                                                                                                 |\n",
    "| %extra_jars                 |  List        |  Comma separated list of additional Jars to include in the cluster.                                                                                       |\n",
    "| %number_of_workers          |  Integer     |  The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too.                                          |\n",
    "| %glue_version               |  String      |  The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0 (eg: %glue_version 2.0).                               |\n",
    "| %security_config            |  String      |  Define a security configuration to be used with this session.                                                                                            |\n",
    "| %sql                        |  String      |  Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code.                                                            |\n",
    "| %streaming                  |  String      |  Changes the session type to Glue Streaming.                                                                                                              |\n",
    "| %etl                        |  String      |  Changes the session type to Glue ETL.                                                                                                                    |\n",
    "| %status                     |              |  Returns the status of the current Glue session including its duration, configuration and executing user / role.                                          |\n",
    "| %stop_session               |              |  Stops the current session.                                                                                                                               |\n",
    "| %list_sessions              |              |  Lists all currently running sessions by name and ID.                                                                                                     |\n",
    "| %worker_type                |  String      |  Standard, G.1X, *or* G.2X. number_of_workers must be set too. Default is G.1X.                                                                           |\n",
    "| %spark_conf                 |  String      |  Specify custom spark configurations for your session. E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer.                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "Installed kernel version: 0.37.0 \n",
      "Previous number of workers: 5\n",
      "Setting new number of workers to: 8\n",
      "Previous worker type: G.1X\n",
      "Setting new worker type to: G.2X\n"
     ]
    }
   ],
   "source": [
    "%number_of_workers 8\n",
    "%worker_type G.2X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::078881089437:role/GlueNotebookRole\n",
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: G.2X\n",
      "Number of Workers: 8\n",
      "Session ID: fbb0f648-5813-49f7-9dd5-157215bd8479\n",
      "Job Type: glueetl\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.37.0\n",
      "--enable-glue-datacatalog true\n",
      "Waiting for session fbb0f648-5813-49f7-9dd5-157215bd8479 to get into ready status...\n",
      "Session fbb0f648-5813-49f7-9dd5-157215bd8479 has been created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data from Data Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_table = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database='steam_reviews',\n",
    "    table_name='reviews'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "|-- app_id: long\n",
      "|-- app_name: string\n",
      "|-- review_text: string\n",
      "|-- review_score: long\n",
      "|-- review_votes: long\n"
     ]
    }
   ],
   "source": [
    "reviews_table.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Dynamic Frame to a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------------+------------+------------+\n",
      "|app_id|      app_name|         review_text|review_score|review_votes|\n",
      "+------+--------------+--------------------+------------+------------+\n",
      "|    10|Counter-Strike|     Ruined my life.|           1|           0|\n",
      "|    10|Counter-Strike|This will be more...|           1|           1|\n",
      "|    10|Counter-Strike|This game saved m...|           1|           0|\n",
      "|    10|Counter-Strike|• Do you like ori...|           1|           0|\n",
      "|    10|Counter-Strike|        Easy to l...|           1|           1|\n",
      "+------+--------------+--------------------+------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# convert the dynamic dataframe to a Spark dataframe\n",
    "df = reviews_table.toDF()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "### 2.1 Check for null values\n",
    "Here we check for empty string values and blank cell values in the `review_text` and `app_name` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7419\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.filter((df[\"review_text\"] == \"\") | (df[\"review_text\"] == ' ') | df[\"review_text\"].isNull() | isnan(df[\"review_text\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183234\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"app_name\"] == \"\") | (df[\"app_name\"] == ' ') | df[\"app_name\"].isNull() | isnan(df[\"app_name\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6409687\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"review_text\"] != \"\") & (df[\"review_text\"] != ' ') & df[\"review_text\"].isNotNull() & ~isnan(df[\"review_text\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7419\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"review_text\"] == \"\") | (df[\"review_text\"] == ' ')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6417106\n"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6417106\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"review_text\"] != \"\") | (df[\"review_text\"] != ' ') | df[\"review_text\"].isNotNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Drop rows that contain empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.filter((df[\"review_text\"] != \"\") & (df[\"review_text\"] != ' ') & df[\"review_text\"].isNotNull() & ~isnan(df[\"review_text\"]))\n",
    "df = df.filter((df[\"app_name\"] != \"\") & (df[\"app_name\"] != ' ') & df[\"app_name\"].isNotNull() & ~isnan(df[\"app_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that records with empty strings were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"review_text\"] == \"\") | (df[\"review_text\"] == ' ') | df[\"review_text\"].isNull() | isnan(df[\"review_text\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"app_name\"] == \"\") | (df[\"app_name\"] == ' ') | df[\"app_name\"].isNull() | isnan(df[\"app_name\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6226617\n"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Trim whitespace from both ends of the review text\n",
    "Create a new dataframe called `df_records` and trim whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim, lower\n",
    "df_records = df.withColumn(\"review_text\", trim(df.review_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Remove \"Early Access Review\" records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_records = df_records.filter(df_records[\"review_text\"] != \"Early Access Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5238645\n"
     ]
    }
   ],
   "source": [
    "df_records.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Reduce data to top 20 games\n",
    "For our analysis we will focus on the top 20 games based on number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top20_games_list = list(df_records.groupby('app_name').count().sort('count', ascending = False).select('app_name').toPandas()['app_name'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAYDAY 2', 'Terraria', 'Dota 2', 'Rocket League', 'Undertale', 'Left 4 Dead 2', 'Warframe', 'Grand Theft Auto V', 'Portal 2', 'Fallout: New Vegas', 'Arma 3', 'The Witcher 3: Wild Hunt', 'BioShock Infinite', 'DARK SOULS™: Prepare To Die Edition', \"Garry's Mod\", 'Insurgency', 'Mount & Blade: Warband', 'FTL: Faster Than Light', \"No Man's Sky\", 'Call of Duty: Black Ops III']\n"
     ]
    }
   ],
   "source": [
    "top20_games_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Filter dataframe for top 20 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_records = df_records.filter(F.col('app_name').isin(top20_games_list)).sort('app_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846712\n"
     ]
    }
   ],
   "source": [
    "df_records.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lowercase the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_records = df_records.withColumn(\"review_text\", lower(df_records.review_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+------------+------------+\n",
      "|app_id|app_name|         review_text|review_score|review_votes|\n",
      "+------+--------+--------------------+------------+------------+\n",
      "|107410|  Arma 3|my first day in a...|           1|           1|\n",
      "|107410|  Arma 3|if you have frien...|           1|           0|\n",
      "|107410|  Arma 3|recommending this...|           1|           1|\n",
      "|107410|  Arma 3|can't tell you if...|           1|           1|\n",
      "|107410|  Arma 3|i wanna play a zo...|           1|           1|\n",
      "|107410|  Arma 3|i have owned this...|           1|           1|\n",
      "|107410|  Arma 3|it's not a good '...|           1|           1|\n",
      "|107410|  Arma 3|oh man. where to ...|           1|           1|\n",
      "|107410|  Arma 3|having accumulate...|           1|           1|\n",
      "|107410|  Arma 3|after some 1,400 ...|           1|           1|\n",
      "|107410|  Arma 3|this game made me...|           1|           0|\n",
      "|107410|  Arma 3|this is quite pos...|           1|           0|\n",
      "|107410|  Arma 3|do not get this g...|           1|           0|\n",
      "|107410|  Arma 3|children play cal...|           1|           0|\n",
      "|107410|  Arma 3| ├professors review┤|           1|           1|\n",
      "|107410|  Arma 3|this is not a gam...|           1|           1|\n",
      "|107410|  Arma 3|if you're coming ...|           1|           0|\n",
      "|107410|  Arma 3|my first game on ...|           1|           0|\n",
      "|107410|  Arma 3|i spent several y...|           1|           1|\n",
      "|107410|  Arma 3|joined exile seve...|           1|           0|\n",
      "+------+--------+--------------------+------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_records.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Upload Data\n",
    "### 4.1 Convert PySpark dataframe to Dynamic Frame prior to uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "dyf_records = DynamicFrame.fromDF(df_records, glueContext, \"nested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Upload Dynamic Frame to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<awsglue.dynamicframe.DynamicFrame object at 0x7f27f793ef10>\n"
     ]
    }
   ],
   "source": [
    "# write down the data in a Dynamic Frame to S3 location. \n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "                        frame = dyf_records, # dynamic frame\n",
    "                        connection_type=\"s3\", \n",
    "                        connection_options = {\"path\": \"s3://siads696-wi23-steam-data/write_down_dyf_to_s3/\"}, \n",
    "                        format = \"csv\", # write as a csv\n",
    "                        format_options={\n",
    "                            \"separator\": \",\"\n",
    "                            },\n",
    "                        transformation_ctx = \"datasink2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
